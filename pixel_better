import cv2
import numpy as np
from picamera2 import Picamera2
import time
import os
import datetime
import csv

DETECTION_MODE = "canny"  # Global variable to track detection mode

PIXELS_PER_METER = 38043    # Calculate your pixels per meter

# Load calibration parameters from NPZ file
calibration_path = 'camera_calibration.npz'
calibration_data = np.load(calibration_path)
camera_matrix = calibration_data['camera_matrix']
dist_coeffs = calibration_data['dist_coeffs']

# Convert x cm diameter to pixel radius
CM_DIAMETER = 4
RADIUS_PIXELS = int((CM_DIAMETER / 2) * PIXELS_PER_METER / 100)  # Convert cm to meters, then to pixels

# Define your regions of interest (ROIs) as center points (x, y)
# Format: [(center_x, center_y), ...]
ROI_CENTERS = [
    # (450, 500),      # ROI 1: center point
    # (1850, 500),     # ROI 2: center point
    # (3350, 500),     # ROI 3: center point
    # (450, 1775),    # ROI 4: center point
    (1850, 1100)     # ROI 5: center point
    # (3350, 1775)
]

# ROI names remain the same
ROI_NAMES = ["Pixel_intensity_plaBeads"]


def calculate_intensity_metrics(roi_image):
    """
    Calculate intensity metrics for an ROI
    
    Args:
        roi_image: Image of the ROI
        
    Returns:
        intensity_matrix: Matrix of pixel intensities
        avg_intensity: Average intensity of all pixels in the ROI
        std_intensity: Standard deviation of intensities
        min_intensity: Minimum intensity value
        max_intensity: Maximum intensity value
    """
    # Convert to grayscale if image is in color
    if len(roi_image.shape) == 3:
        gray_roi = cv2.cvtColor(roi_image, cv2.COLOR_BGR2GRAY)
    else:
        gray_roi = roi_image
    
    # Create a mask for non-zero pixels (part of the ROI)
    mask = np.where(gray_roi > 0, 1, 0).astype(np.uint8)
    
    # Extract intensity matrix (only for pixels in the ROI)
    intensity_matrix = gray_roi * mask
    
    # Calculate statistics (only for pixels in the ROI)
    non_zero_pixels = cv2.countNonZero(mask)
    if non_zero_pixels > 0:
        # Get only the non-zero values for statistics
        non_zero_values = intensity_matrix[intensity_matrix > 0]
        avg_intensity = np.mean(non_zero_values)
        std_intensity = np.std(non_zero_values)
        min_intensity = np.min(non_zero_values)
        max_intensity = np.max(non_zero_values)
    else:
        avg_intensity = std_intensity = min_intensity = max_intensity = 0
    
    return intensity_matrix, avg_intensity, std_intensity, min_intensity, max_intensity

def undistort_image(img):
    """
    Apply camera calibration to undistort an image
    
    Args:
        img: Image to undistort
        
    Returns:
        Undistorted image
    """
    if 'camera_matrix' not in calibration_data or 'dist_coeffs' not in calibration_data:    
        raise ValueError("Calibration file is missing 'camera_matrix' or 'dist_coeffs'")

    if img is None:
        raise ValueError("Input image is None. Make sure camera frame was captured correctly.")

    h, w = img.shape[:2]
    
    # Get optimal new camera matrix
    new_camera_matrix, roi = cv2.getOptimalNewCameraMatrix(camera_matrix, dist_coeffs, (w, h), 1, (w, h))
    
    # Convert the image to the expected format
    img_mat = cv2.UMat(img)
    
    # Undistort the image
    undistorted = cv2.undistort(img_mat, camera_matrix, dist_coeffs, None, new_camera_matrix)
    
    # Convert back to CPU array for further processing
    undistorted = undistorted.get()
    
    # Crop the image based on ROI from getOptimalNewCameraMatrix
    x, y, w, h = roi
    undistorted = undistorted[y:y+h, x:x+w]
    
    return undistorted



def connect_edges_with_closing(edges, kernel_size=(5, 5)):
    """
    Connect edges from Canny edge detection using morphological closing.
    
    Args:
        edges: Binary edge image from Canny detector
        kernel_size: Size of the morphological kernel
        
    Returns:
        Processed image with connected edges
    """
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernel_size)
    closed_edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)
    return closed_edges

def connect_edges_multi_kernel(edges):
    # Start with small kernel, progressively increase
    result = edges.copy()
    for size in [3, 5, 7]:
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (size, size))
        result = cv2.morphologyEx(result, cv2.MORPH_CLOSE, kernel)
    return result

def canny(image, low_threshold=120, high_threshold=170, aperture_size=3):
    # Make a copy of the original image
    original = image.copy()
    
    # Convert to grayscale
    gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)
    
    # Apply Gaussian blur to reduce noise
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    
    # Apply Canny edge detector
    edges = cv2.Canny(blurred, low_threshold, high_threshold, apertureSize=aperture_size)
    
    # Connect edges using closing algorithms
    connected_edges = connect_edges_multi_kernel(edges)
    return connected_edges

def area_calc(connected_edges, min_area=100, max_area=23605):
    """
    Calculate the total area of regions enclosed by connected edges.
    
    Args:
        connected_edges: Binary image with connected edges from Canny detection
        minimum_area: Minimum contour area to consider (filters out noise)
        
    Returns:
        total_area: Total area of all significant contours in pixels
        contours: List of significant contours found
    """
    # Create a copy of the connected edges
    edges_copy = connected_edges.copy()

    contours, _ = cv2.findContours(edges_copy, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    # cv2.RETR
    
    significant_contours = []
    total_area = 0
    
    for contour in contours:
        area = cv2.contourArea(contour)
        if area > min_area and area < max_area:
            significant_contours.append(contour)
            total_area += area
            
    area_m2 = (total_area / (PIXELS_PER_METER ** 2))*10000  # Convert to cmÂ²
    
    return total_area, significant_contours, area_m2

def process_roi(frame, roi_center):
    """Process a single circular region of interest"""
    center_x, center_y = roi_center
    
    # Create a mask for the circular ROI
    mask = np.zeros(frame.shape[:2], dtype=np.uint8)
    cv2.circle(mask, (center_x, center_y), RADIUS_PIXELS, 255, -1)
    
    # Create a rectangular bounding box for the circle
    x1 = max(0, center_x - RADIUS_PIXELS)
    y1 = max(0, center_y - RADIUS_PIXELS)  # Fixed: changed center_x to center_y
    x2 = min(frame.shape[1], center_x + RADIUS_PIXELS)
    y2 = min(frame.shape[0], center_y + RADIUS_PIXELS)
    
    # Verify valid coordinates
    if x1 >= x2 or y1 >= y2:
        raise ValueError(f"Invalid ROI coordinates: ({x1}, {y1}, {x2}, {y2})")
        
    # First crop both frame and mask
    cropped_frame = frame[y1:y2, x1:x2]
    cropped_mask = mask[y1:y2, x1:x2]
    
    # Verify cropped frame is valid
    if cropped_frame is None or cropped_frame.size == 0:
        raise ValueError("Invalid cropped frame")
        
    # Apply mask to get the ROI
    masked_edges = cv2.bitwise_and(cropped_frame, cropped_frame, mask=cropped_mask)
    
    # Calculate intensity metrics from the masked ROI
    intensity_matrix, avg_intensity, std_intensity, min_intensity, max_intensity = calculate_intensity_metrics(masked_edges)
    
    # Apply edge detection to masked ROI - store both raw edges and connected edges
    raw_edges = canny(masked_edges)  # Store the raw Canny edges
    edges = connect_edges_multi_kernel(raw_edges)  # Connect the edges for area calculation
    
    # Calculate area in ROI
    pixel_area, contours, area_cm2 = area_calc(edges)
    
    # Create visualization
    contour_image = masked_edges.copy()
    cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)
    
    return raw_edges, contour_image, pixel_area, contours, area_cm2, (x1, y1, x2-x1, y2-y1), intensity_matrix, avg_intensity, std_intensity, min_intensity, max_intensity

def setup_directories(test_id):
    """Set up all needed directories within a test-specific directory"""
    # Get test name from user
    test_name = input("Enter test name: ")
    
    # Create main test directory with test name
    test_dir = f"{test_name}_test_{test_id}"
    
    # Define subdirectories within the test directory
    subdirs = [
        "images/pi_timelapse",
        "images/roi/edges",
        "images/roi/contours", 
        "images/roi/intensity",
        "data/csv",
        "data/intensity_matrix"
    ]
    
    # Create all directories
    for subdir in subdirs:
        full_path = os.path.join(test_dir, subdir)
        if not os.path.exists(full_path):
            os.makedirs(full_path)
            
    return test_dir, test_name

# Replace the resize_half function with resize_quarter
def resize_quarter(image):
    """Resize an image to quarter of its original dimensions"""
    h, w = image.shape[:2]
    return cv2.resize(image, (w//4, h//4))

def visualize_intensity(intensity_matrix, window_name):
    """
    Create a visualization of pixel intensities
    
    Args:
        intensity_matrix: Matrix of pixel intensities
        window_name: Name for the visualization window
    
    Returns:
        heatmap: The generated heatmap visualization
    """
    # Normalize the intensity matrix to 0-255 range for visualization
    normalized = cv2.normalize(intensity_matrix, None, 0, 255, cv2.NORM_MINMAX)
    
    # Convert to heatmap colorscheme
    heatmap = cv2.applyColorMap(normalized.astype(np.uint8), cv2.COLORMAP_JET)
    
    # Add text with min/max values
    min_val = np.min(intensity_matrix[intensity_matrix > 0])
    max_val = np.max(intensity_matrix)
    mean_val = np.mean(intensity_matrix[intensity_matrix > 0])
    
    # Add text to the image
    cv2.putText(heatmap, f"Min: {min_val:.1f}", (10, 20), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    cv2.putText(heatmap, f"Max: {max_val:.1f}", (10, 40), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    cv2.putText(heatmap, f"Mean: {mean_val:.1f}", (10, 60), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    
    # Display the heatmap
    display_heatmap = cv2.resize(heatmap, (heatmap.shape[1]//2, heatmap.shape[0]//2))
    cv2.imshow(window_name, display_heatmap)
    
    return heatmap

def main(test_id="001"):
    try:
        # Set up directories and get base test directory
        test_dir, test_name = setup_directories(test_id)
        
        # Update CSV file paths
        area_csv_file = os.path.join(test_dir, "data/csv", f"{test_name}_area_metrics.csv")
        intensity_csv_file = os.path.join(test_dir, "data/csv", f"{test_name}_intensity_metrics.csv")
        
        # Setup area CSV
        with open(area_csv_file, 'w', newline='') as f:
            writer = csv.writer(f)
            header = ['timestamp', 'elapsed_time']
            for name in ROI_NAMES:
                header.extend([f'{name}_pixel_area', f'{name}_area_cm2'])
            writer.writerow(header)
        
        # Setup intensity CSV
        with open(intensity_csv_file, 'w', newline='') as f:
            writer = csv.writer(f)
            header = ['timestamp', 'elapsed_time']
            for name in ROI_NAMES:
                header.extend([f'{name}_avg_intensity', f'{name}_std_intensity', 
                             f'{name}_min_intensity', f'{name}_max_intensity'])
            writer.writerow(header)

        # Initialize camera
        picam2 = Picamera2()
        config = picam2.create_still_configuration(
            main={"size": (3840, 2160)},
            controls={"AfMode": 0}
        )
        
        picam2.configure(config)
        interval = 10  # Interval in seconds
        last_capture_time = 0            # Add a second timer for screenshot capture
        last_screenshot_time = 0  
        screenshot_interval = 900 # 30 minutes in seconds
        roi_interval = 60
        last_roi_time = 0 
        
        picam2.start()
        lens_position =2.8  # Initial lens position for objects ~5cm away
        lens_step = 0.05     # Smaller step size for finer control
        picam2.set_controls({"LensPosition": lens_position})

        print("Starting edge detection. Controls:")
        print("'q' - quit")
        print("'s' - save current frame")
        print("'+' - increase focus")
        print("'-' - decrease focus")
        time.sleep(2)
        
        # Use the original ROI centers directly
        roi_centers = ROI_CENTERS
        
        start_time = time.time()
        
        while True:
            # Get current time at start of loop
            current_time = time.time()
            
            cal_frame = picam2.capture_array() ##Normal Frame     

            #these two lines are for the callibrated camera (NOT YET WORKING)
            # frame = picam2.capture_array()
            # cal_frame = undistort_image(frame) ##calibrated Frame
    

            display_frame = cal_frame.copy()
            
            # Process each ROI
            roi_results = []
            intensity_results = []
            
            for i, center in enumerate(ROI_CENTERS):
                center_x, center_y = center
                
                # Draw ROI circle on display frame
                cv2.circle(display_frame, (center_x, center_y), RADIUS_PIXELS, (255, 0, 0), 2)
                cv2.putText(display_frame, ROI_NAMES[i], (center_x - RADIUS_PIXELS, center_y - RADIUS_PIXELS - 10), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)
                
                # Process ROI and get all metrics
                edges, contour_image, pixel_area, contours, area_cm2, roi_box, intensity_matrix, avg_intensity, std_intensity, min_intensity, max_intensity = process_roi(cal_frame, center)
                
                roi_results.append((edges, contour_image, pixel_area, contours, area_cm2, roi_box))
                intensity_results.append((intensity_matrix, avg_intensity, std_intensity, min_intensity, max_intensity))

            # Resize display frame to 1080p for smoother display
            display_frame = cv2.resize(display_frame, (1920, 1080))

            # Show main frame with ROI boxes
            cv2.imshow("Main View", display_frame)

            # Show windows for each ROI's edges, contours and intensity
            for i, (raw_edges, contour_image, _, _, _, _) in enumerate(roi_results):
                # Resize ROI windows for display
                display_edges = cv2.resize(raw_edges, (raw_edges.shape[1]//2, raw_edges.shape[0]//2))
                display_contours = cv2.resize(contour_image, (contour_image.shape[1]//2, contour_image.shape[0]//2))
                
                # Show raw Canny edges and contour visualization
                cv2.imshow(f"ROI {i+1} - {ROI_NAMES[i]} Canny Edges", display_edges)
                cv2.imshow(f"ROI {i+1} - {ROI_NAMES[i]} Detected Contours", display_contours)

            # Show and save intensity visualizations
            if current_time - last_roi_time >= roi_interval:
                timestamp = datetime.datetime.now().strftime("%H_%M_%S")
                for i, (intensity_matrix, _, _, _, _) in enumerate(intensity_results):
                    # Create and show intensity visualization
                    heatmap = visualize_intensity(intensity_matrix, f"ROI {i+1} - {ROI_NAMES[i]} Intensity")
                    
                    # Save intensity visualization
                    intensity_path = os.path.join(test_dir, "images/roi/intensity", f"{timestamp}_ROI_{i+1}_intensity.jpg")
                    resized_intensity = resize_quarter(heatmap)
                    cv2.imwrite(intensity_path, resized_intensity)
            
            current_time = time.time()
            key = cv2.waitKey(1) & 0xFF
            
            # Handle key presses
            if key == ord('q'):
                break
            elif key == ord('s'):
                timestamp = datetime.datetime.now().strftime("%H_%M_%S")
                
                # Save main frame with half resolution
                main_img_path = os.path.join(test_dir, "images/pi_timelapse", f"{timestamp}_main.jpg")
                resized_frame = resize_quarter(cal_frame)
                cv2.imwrite(main_img_path, resized_frame)
                
                # Save each ROI with half resolution
                for i, (edges, contour_image, pixel_area, _, area_cm2, _) in enumerate(roi_results):
                    edge_path = os.path.join(test_dir, "images/roi/edges", f"{timestamp}_ROI_{i+1}_edges.jpg")
                    contour_path = os.path.join(test_dir, "images/roi/contours", f"{timestamp}_ROI_{i+1}_contours.jpg")
                    # Resize the images to half size
                    resized_edge = resize_quarter(edges)
                    resized_pic = resize_quarter(contour_image)
                    cv2.imwrite(edge_path, resized_edge)
                    cv2.imwrite(contour_path, resized_pic)
                
                print(f"Manually captured at {timestamp}")
                for i, (_, _, pixel_area, _, area_cm2, _) in enumerate(roi_results):
                    print(f"{ROI_NAMES[i]}: {pixel_area:.2f} px | {area_cm2:.2f} cmÂ²")
            # In the key handling section:
            elif key == ord('+') or key == ord('='):
              lens_position = min(10.0, lens_position + lens_step)
              picam2.set_controls({"LensPosition": lens_position})
              print(f"Lens position: {lens_position:.2f}")
            elif key == ord('-') or key == ord('_'):
              lens_position = max(0.0, lens_position - lens_step)
              picam2.set_controls({"LensPosition": lens_position})
              print(f"Lens position: {lens_position:.2f}")
                    
            # Screenshot capture every 30 minutes
            if current_time - last_screenshot_time >= screenshot_interval:
                timestamp = datetime.datetime.now().strftime("%H_%M_%S")
                main_img_path = os.path.join(test_dir, "images/pi_timelapse", f"{timestamp}_main.jpg")
                resized_frame = resize_quarter(cal_frame)
                cv2.imwrite(main_img_path, resized_frame)
                last_screenshot_time = current_time
                print(f"Screenshots captured at {timestamp}")

            # Take screenshots of ROI
            if current_time - last_roi_time >= roi_interval:
                timestamp = datetime.datetime.now().strftime("%H_%M_%S")
                for i, (edges, contour_image, pixel_area, _, area_cm2, _) in enumerate(roi_results):
                    edge_path = os.path.join(test_dir, "images/roi/edges", f"{timestamp}_ROI_{i+1}_edges.jpg")
                    contour_path = os.path.join(test_dir, "images/roi/contours", f"{timestamp}_ROI_{i+1}_contours.jpg")
                    # Resize the taken images from camera
                    resized_edge = resize_quarter(edges)
                    resized_pic = resize_quarter(contour_image)
                    cv2.imwrite(edge_path, resized_edge)
                    cv2.imwrite(contour_path, resized_pic)
                last_roi_time = current_time
                
                # Also capture data for CSV when taking ROI screenshots
                if current_time - last_capture_time >= interval:
                    timestamp = datetime.datetime.now().strftime("%H_%M_%S")
                    elapsed_time = current_time - start_time
                    
                    # Save ROI data
                    row_data = [timestamp, f"{elapsed_time:.2f}"]
                    
                    # Add each ROI's data to CSV row
                    for i, (_, _, pixel_area, _, area_cm2, _) in enumerate(roi_results):
                        row_data.extend([pixel_area, area_cm2])
                        print(f"{ROI_NAMES[i]}: {pixel_area:.2f} px | {area_cm2:.2f} cmÂ²")
                    
                    # Write to CSV
                    with open(area_csv_file, 'a', newline='') as f:
                        writer = csv.writer(f)
                        writer.writerow(row_data)
                    
                    last_capture_time = current_time

            # Data capture for CSV every 10 seconds
            if current_time - last_capture_time >= interval:
                timestamp = datetime.datetime.now().strftime("%H_%M_%S")
                elapsed_time = current_time - start_time
                
                # Save area data
                area_row = [timestamp, f"{elapsed_time:.2f}"]
                for _, _, pixel_area, _, area_cm2, _ in roi_results:
                    area_row.extend([pixel_area, area_cm2])
                
                # Save intensity data
                intensity_row = [timestamp, f"{elapsed_time:.2f}"]
                for _, avg_int, std_int, min_int, max_int in intensity_results:
                    intensity_row.extend([avg_int, std_int, min_int, max_int])
                
                # Save intensity matrices to separate files
                for i, (intensity_matrix, _, _, _, _) in enumerate(intensity_results):
                    matrix_filename = os.path.join(
                        test_dir,
                        "data/intensity_matrix",
                        f"{timestamp}_ROI_{i+1}_matrix.npy"
                    )
                    np.save(matrix_filename, intensity_matrix)
                
                # Write to CSV files
                with open(area_csv_file, 'a', newline='') as f:
                    writer = csv.writer(f)
                    writer.writerow(area_row)
                
                with open(intensity_csv_file, 'a', newline='') as f:
                    writer = csv.writer(f)
                    writer.writerow(intensity_row)
                
                last_capture_time = current_time
            
            if key == ord('q'):
                break

    except Exception as e:
        print(f"Error: {e}")
    finally:
        picam2.stop()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    test_id = input("Enter test ID (e.g., 001): ")
    main(test_id)



